[多级反馈队列（最优）](#多级反馈队列（最优))


进程调度算法：先来先服务，短作业优先，时间片轮转算法，多级反馈队列

页面置换算法： 先进先出置换算法FIFO,最近最少使用置换LRU

1、进程与线程比较
---
（1）进程和线程的关系

   进程是资源分配的基本单位，线程是调度的基本单位；从内存角度来讲，多进程中，所有的子进程拥有各自的内存空间，对32位系统而言也就是完整的4G虚拟地址；而对于一个进程中的多个线程，所有线程工用进程的内存空间。


（2）父进程和子进程的关系？子进程复制了父进程的那些东西？PCB？

答：子进程复制了父进程的所有数据(代码段、数据段、BSS、堆、栈)，从内存的角度来讲，子进程拥有和父进程相同的虚地址，这就解释了同一段地址却存储不同的值。每一个进程产生都有自己的虚拟地址空间，映射到不同的物理空间。多进程时，子进程复制了父进程的虚拟地址，虽然虚拟地址相同，但是映射的物理空间却是不一样的，&操作返回的是虚拟地址。

每个进程在内核中都有一个进程控制块（PCB）来维护进程相关的信息，Linux内核的进程控制块是task_struct结构体。

```cpp

main(){
    char str[4]="asd";
    pid_t pid=fork();
    if(pid==0){
        str[0]='b';
        printf("子进程中str=%s\n",str);
        printf("子进程中str指向的首地址:%x\n",(unsigned int)str);
    }
    else{
        sleep(1);
        printf("父进程中str=%s\n",str);
        printf("父进程中str指向的首地址:%x\n",(unsigned int)str);
    }

```

补充：`写时复制`-------->fork实际情况，复制内核数据结构+页表+写时复制

fork之后，子进程并不是一次性地复制父进程的所有东西，这样效率太低。linux采用的是写时复制技术，以减少fork时父进程空间进程整体复制带来的开销。

一般CPU都是以“页”为单位分配空间的，像Intel的CPU，其一页在通常情况下是4K字节大小，而无论是数据段还是堆栈段都是由许多“页”构成的，fork函数复制这两个段，只是“逻辑”上的，并非“物理”上的，也就是说，实际执行fork()时，物理空间上两个进程的数据段和堆栈段都还是共享着的，都是指向同一片物理地址。如果父进程fork出N个子进程，那么这些子进程都只是通过指针指向和父进程一样的物理页中，相当于是只读的。只有当一个子进程要修改自己的这个副本，那么会产生一个缺页中断，这个进程就会复制这份资源到自己的进程空间进行修改，而其他进程仍然共享那份没有修改过的资源，当然，这个修改是以页为大小单位进行修改的，也不是全部复制过来。如果所以进程不需要修改那份资源，则不需要进行复制。


（3）fork和vfork，以及clone的关系？

答：
* fork()是将父进程的全部资源复制给了子进程。会复制父进程的地址空间、已打开文件描述符、命名空间
* clone只是复制了一小部分必要的资源。在调用clone时可以通过参数控制要复制的对象。---->pthread_create中就是调用了clone创建子线程
* vfork共享父进程的地址空间，一般采用vfork()的子进程，都会紧接着执行execv启动一个全新的进程，该进程的进程空间与父进程完全独立不相干，所以不需要复制父进程资源空间，因为vfork主要用于为了让子进程exec，exec之后子进程会用新程序的数据将内存重新刷一遍，这样它就有了自己的地址空间。子进程exec之后返回，这个时候父进程就认为子进程“结束”了，自己开始运行。实际上子进程继续在一个完全独立的空间运行着。举个例子，比如在一个聊天程序中，弹出了一个视频播放器。你说视频播放器要继承你的聊天程序的进程空间的资源干嘛？
* vfork与fork的区别包括两方面，内存角度：fork实际情况，复制内核数据结构+页表+写时复制。而vfork更少，只是复制内核数据结构，即便fork所有子对象都不写时复制，那vfork也比fork省内存。父子进程运行角度：fork之后父进程和子进程哪个先运行是未知的，而vfork后，父进程保证子进程先执行，等子进程调用exit或exec之后，父进程才运行。

（4）进程和线程的优缺点，各适用于什么场合？
答：

（5）多进程和多线程？
答：
场景1：主进程accpet()返回客户端sock，这时由于子进程复制父进程的栈空间，然后在子进程中copy一份，所以在子进程中可以直接对sock进行操作，哪怕此时父进程改变sock的值；但是对于主线程而言，由于子线程没有自己的栈空间，只是共用父线程的空间，所以如果子线程在读取sock时父线程接受了另一个客户端请求覆盖了该值，则子线程无法继续处理上一次的连接任务了。改进的办法是子线程立马复制val的值在自己的栈区，但父线程必须保证子线程复制动作完成之后再执行新的accept()。这又得发生线程间通信，子线程复制完成后主动通知父线程。

场景2：多进程环境间完全独立，要实现通信的话就得采用进程间的通信方式，它们通常都是耗时间的。而线程则不用任何手段数据就是共享的。当然多个子线程在同时执行写入操作时需要实现互斥，否则数据就写“脏”了。

（6）信号量和mutex

 (7)进程切换为什么开销大?
 
 答：必须说到TLB。


1.1 操作系统为什么要分用户态和内核态？
---
在CPU的所有指令中，有一些指令是非常危险的，如果错用，将导致整个系统崩溃。比如：清内存、设置时钟等。为了防止异常，Intel的CPU将特权级别分为4个级别：RING0,RING1,RING2,RING3。对于那些危险的指令，只允许操作系统及其相关模块使用。比如处于用户运行态（用户态）。即此时处理器在特权级最低的（3级）用户代码中运行。

用户态切换到内核态的3种方式：中断，系统调用，异常

比如系统调用：open打开文件描述符，而write、read等系统调用函数再对这个文件描述符进行操作。库函数调用主要使用函数fopen打开一个文件，然后再返回一个指向文件的指针，而fwrite、fread等库函数再对这个指针进行操作。


2、进程间通信
---
进程间的通信方式有这样几种：

A.共享内存    B.消息队列    C.信号量    D.有名管道    E.无名管道    F.信号  G.文件        H.socket

线程间的通信方式上述进程间的方式都可沿用，且还有自己独特的几种：

A.互斥量      B.自旋锁      C.条件变量  D.读写锁      E.线程信号  G.全局变量

进程间通信分为两大类，第一类是在一台主机上的不同进程：管道、命名管道、消息队列、共享内存、信号量、信号

第二类是在两台主机上：socket

- 管道是在父子进程中通信的，是半双工的，如果需要全双工，那么就需要建立两个管道；优点 不需要加锁 缺点 默认缓冲区太小，只有4k

- 命名管道是在不相关的进程之间，通过管道号进行通信，也是半双工。由于进程间不能共享全局变量，所以只能用通过HTTTP请求或写文件的方式告知另一个进程你申请的管道读写文件描述符号。用FIFO让一个服务器和多个客户端进行交流时候，每个客户在向服务器发送信息前建立自己的读管道，或者让服务器在得到数据后再建立管道。使用客户的进程号（pid）作为管道名是一种常用的方法。客户可以先把自己的进程号告诉服务器，然后再到那个以自己进程号命名的管道中读取回复。

- 消息队列：双方协商好传递消息的数据类型，通过key进行连接。key值属于要通信的进程双方互相沟通好的，作为在内核里找到它们专属的消息队列的桥梁。比如父子双方都需要收发消息，通过消息中的type进行区分，比如一个任务分派进程，创建了若干个执行子进程，不管是父进程发送分派任务的消息，还是子进程发送任务执行的消息，都将type设置为目标进程的pid，因为msgrcv可以指定只接收消息类型为type的消息，这样就实现了子进程只接收自己的任务，父进程只接收任务结果

- 共享内存：唯一不在内核缓存区进行的通信，所以速度也是最快的，开发中最常用的。

共享内存的方式像极了多线程中线程对全局变量的访问，对这块临界区的访问也要通过信号量来进行进程同步	

```cpp
消息队列   最大长度64k，最大16条
int msgget(key_t key，int msgflag);
//创建消息队列或者获取消息队列,key是队列名，msgflag是9位权限位 rwx rwx rwx

int main1()
{
    int msgqid=msgget(0x1234,0666);//创建消息队列或者获取消息队列
    if(errno == ENOENT)
    {
        printf("消息队列不存在")；//没有指定创建且没有消息队列返回
    } 
}
int main2()
{
    int msgqid=msgget(0x1234,0666|IPC_CREAT);//指定创建
    if(errno == ENOENT)
    {
        printf("消息队列不存在")；
    } 
}
int main3()
{
    int msgqid=msgget(0x1234,0666|IPC_CREAT|IPC_EXCL);//开发中优先用这个
    //不存在则创建，存在则提醒已经存在
    if(errno == ENOENT)
    {
        printf("消息队列不存在")；
    } 
}
int msgctl();
int main4()
{
    int msgqid=msgget(0x1234,0666);
    if(errno == ENOENT)
    {
        printf("消息队列不存在")；
    } 
    struct msqid_ds buf;
    int ret = magctl(msgid,IPC_STAT,&buf);//传出到buf中，获取对消息队列的控制
}
int msgsnd();
int msgrcv();
```
```cpp
管道======》都是linux内核的缓冲区
管道是半双工的，如果双方需要通信，那么就建立两个管道
管道的读写可以设置成阻塞/非阻塞
int main()
{
    int pipefd[2];
    int ret=pipe(pipefd);//创建管道，fd1写，fd0读
    int pid=fork();
    if(pid == 0)
    {
        close(pipefd[0]);
        write(pipefd[1],"hdsjdskjhdsjk",6);//rw
        close(pipefd[1]);
    }
    close(pipefd[1]);
    char buf[1024]={0};
    int n=read(pipefd[0],buf,sizeof(buf));
    close(pipefd[0]);
}

设置非阻塞：
int flag= fcntl(int fd, F_GETFL);//第二个命令cmd是指get set
flag= flag| O_NONBLOCK;
int ret=fcntl( fd, F_SETFL,flag);
```
```cpp
共享内存   ====》不陷入内核，读写涉及加锁，和信号量放在一起
将内核中的缓冲区映射到用户空间，可以选择修改后是否重新同步给内核缓冲区
ipcs-------> nattach  表示有多少个进程连接这个共享内存了


int main3()
{
   int shmid= shmget(0x2234,sizeof(Teacher),0666|IPC_CREAT|IPC_EXCL);
   //不存在则创建，存在则提醒已经存在
    if(errno == ENOENT)
    {
        printf("共享内存不存在")；
    }
    Teacher *p=NULL;
    P=shmat(shmid,NULL,0);//映射到用户空间，p就是共享内存的首地址
}
```
2.2 无名管道的流程
---
int pipe(int fd[2]);

读的一端用fd[0]表示，写的一端用fd[1]表示。通信双方的进程中写数据的一方需要把fd[0]先close掉，读的一方需要先把fd[1]给close掉。

流程：

- 1. 父进程调用 pipe 开辟管道，得到两个文件描述符指向管道的两端。
- 2. 父进程调用 fork 创建子进程，那么子进程也有两个文件描述符指向同一管道。
- 3. 父进程关闭管道读端，子进程关闭管道写端。父进程可以往管道里写，子进程可以从管道里读，管道是用环形队列实现的，数据从写端流入从读端流出，这样就实现了进程间通信。

为什么写端要关闭fd[0]，读端要关闭fd[1]？
---
答：父进程中都有两个文件描述符fd[0]和fd[1]，相当于两个文件描述符的计数都是2。
如果如果写的文件描述符（fd[1]）都关闭了，也就是管道写的引用计数等于0，那么当有进程一直读时，当管道读空了，再次 read 会返回0，正常退出；
但是，如果一开始没有关闭文件描述符，相当于计数一开始为2；当关闭一个文件描述符后，计数为1，那么当有进程一直读时，当管道读空了，再次 read 会返回会阻塞，不能正常退出；	

下面的场景便于思考管道通信的过程：
 
父进程准备写，关闭了读端口。通过写端口向pipe中写入了hello world。然后父进程结束。关闭相关文件（读写）描述符。   如果子进程在关闭写端口的时候，父进程结束时候，写文件描述符引用计数为0。所以子进程再次读取后返回0。子进程结束退出。　　子进程在不关闭写端口的时候，父进程结束时候，写文件描述符引用计数为1（自己的没关闭）。所以子进程再次读取时候陷入阻塞状态。

3、虚拟内存和物理内存
---
虚拟内存地址的大小是与地址总线位数相关，物理内存地址的大小跟物理内存条的容量相关。

假设你的计算机是32位，那么它的地址总线是32位的，也就是它可以寻址0~0xFFFFFFFF（4G）的地址空间，但如果你的计算机只有256M的物理内存0x~0x0FFFFFFF（256M），同时你的进程产生了一个不在这256M地址空间中的地址，那么计算机该如何处理呢？

答：计算机会对虚拟内存地址空间（32位为4G）分页产生页（page），对物理内存地址空间（假设256M）分页产生页帧（page frame），这个页和页帧的大小是一样大的，但是虚拟内存页的个数 > 物理内存页帧的个数。在计算机上有一个页表（page table），就是映射虚拟内存页到物理内存页的，更确切的说是页号到页帧号的映射。操作系统有个页面失效（page fault）功能。当缺页中断时，操作系统通过页面置换算法 找到一个最少使用的页帧（物理内存中），让他失效，并把它写入磁盘（临时保存一下），随后把需要访问的页放到页帧中，并修改页表中的映射，这样就保证所有的页都有被调度的可能了。这就是处理虚拟内存地址到物理内存的步骤。

虚拟内存地址由页号和偏移量组成，那么先把页号映射到页帧，然后在页帧+偏移量组成物理上真正存在的地址。

32位进程的地址空间都是4G，但用户态下只能访问低3G的地址空间，若要访问3G ~ 4G的地址空间则只有进入内核态才行。

linux的内存管理-----伙伴关系+slab
---
为什么要使用虚拟内存？

答：虚拟内存有三个好处。第一是可以虚拟地扩充内存；第二是作业无须一次性全部装入，所以4G的虚拟内存可以运行8G的游戏；第三是作业不用常驻内存，可以通过调度算法换进换出。

`伙伴关系`
为了减少外部碎片，把所有的空闲页面分为大小不同的十个页块，其中每个页块的大小为2幂次个页（4K*2^n），把这些页块用链表相连。每个块链表分别包含大小为1，2，4，8，16，32，64，128，256，512和1024个连续页框的页框块。

（1）页块框地起始地址：
每个页块的第一个页的物理地址是该块大小的整数倍。例如，大小为16个页的块，其起始地址是16*2^12（2^12=4096）的整数倍。

（2）分配页块时：
假设要申请一个256个页的块，先从256个页的链表中查找空闲块，如果没有，就去512个页的链表中找，找到了则将页块分为2个256个页的块，一个分配给应用，另外一个移到256个页的链表中。如果512不存在，接着往上找，如果1024块存在，则将其中的256页作为请求返回，剩余的768分成256块和512块分别插到相应的链表中。如果仍然没有，则返回错误。

（3）页框块在释放时：
会迭代地主动合成为2倍大的单独页框块。两个块称为伙伴需要满足一下条件：
        （1）两个块具有相同的大小
       （2）它们的物理地址是连连续的。
       （3）第一块的第一个页框的物理地址是2*b*2^12的倍数。
       
（4）页块数组的数据结构：
    
 包含一个11元素、元素类型为free_area的一个数组，每个元素对应一块大小。
    
 free_area每个元素中有一个free_list，表示双向循环链表的头，这个双向循环链表集中了大小为2^k页的空闲块对应的页描述符。该链表包含每个空闲页框块（大小为2^k）的起始页框的页描述符。指向链表中相邻元素的指针存放在页描述符的lru字段中。
      
   free_area每个元素还包含一个nr_free字段，它指定了大小为2^k的页框块个数。当然，如果没有大小为2^k的空闲页框块，则nr_free等于0且free_list为空。
          
   一个空闲块的第一个页的描述符的private字段存放了块的order，也就是k。正式由于这个字段，当页框被释放时，内核可以确定这个块的伙伴是否也空闲。如果是的话就可以把两个块合成一个2^(i+1)的块。
   
`slab`
物理内存也是页，每个页大小固定4k，分配时不必是连续地址，但是要尽量选择连续的地址。为了尽量减少不连续情况，采用了“伙伴”关系来管理空闲页面，分配页面必须是2的幂次个页面（1、2、4、8…512页）。内核自身最常使用的内存往往是很小的，比如存放文件描述符、进程描述符、虚拟内存区域描述符等行为所需的内存都远小于一页，用一整个4k内存太浪费，于是提出了slab。Slab在伙伴关系分配的4k内存基础上，将页面（来自于伙伴关系管理的空闲页面链表）撕碎成众多小内存块以供分配，而且当被使用完后，并不直接释放而是被缓存到“存储池”里。伙伴关系可以减小外部碎片，slab可以减小内部碎片
（类似项目中自己实现的内存池＋对象池关系）
          
补充：
`top中虚拟内存VIRT和RES常驻内存的关系？`
VIRT：
进程“需要的”虚拟内存大小，包括进程使用的库、代码、数据，以及malloc、new分配的堆空间和分配的栈空间等；如果new了100M，但是我现在只往里面写1M，这时VIRT增加100M，RES增加1M
RES:
malloc了100M的内存，但是只给其中里面写1M，则RES增加1M
```cpp
#include <iostream>
 
int main()
{
    char * p = new char [1024*1024*512];
    getchar();
    return 0;
 }
 
top结果如下：
PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
401 huyiyang  17   0  523m  916  792 S  0.0  0.0   0:00.00 ./main
```
```cpp
#include <iostream>
 
int main()
{
    char * p = new char [1024*1024*512];
    memset(p, 0, 1024*1024*512);
    getchar();
    return 0;
}
top结果如下：
PID   USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND  
32604 huyiyang  17   0  523m  512m  792 S  0.0 26.2   0:00.33 ./main
```
4、进程的内存管理
---
![示意图](https://github.com/Planck-a/image-folder/blob/master/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/usage.png)
进程用的4G虚拟内存，多个进程创建多个内存空间；这些个空间由一个vm_area_strcut类型的链表链起来，然后在4G地址空间中定位特定内存区域的时候，用的是  红黑树；创建进程fork()、程序载入execve()、映射文件mmap()、动态内存分配malloc()都是分配虚拟内存给进程，这些分配最终都会归结到do_mmap（）函数上，do_mmap判断如果是一个新的空间，则返回vm_area_strcut对象，如果是在某个空间中申请，就合并新内存和老内存。

物理内存也是页，每个页大小固定4k，分配时不必是连续地址，但是要尽量选择连续的地址。为了尽量减少不连续情况，采用了“伙伴”关系来管理空闲页面，分配页面必须是2的幂次个页面（1、2、4、8…512页）。内核自身最常使用的内存往往是很小的，比如存放文件描述符、进程描述符、虚拟内存区域描述符等行为所需的内存都远小于一页，用一整个4k内存太浪费，于是提出了slab。Slab在伙伴关系分配的4k内存基础上，将页面（来自于伙伴关系管理的空闲页面链表）撕碎成众多小内存块以供分配，而且当被使用完后，并不直接释放而是被缓存到“存储池”里。伙伴关系可以减小外部碎片，slab可以减小内部碎片

（内存池＋对象池关系）

slab+伙伴关系:

- 伙伴关系：为了减少外部碎片，把所有的空闲页面分为大小不同的十个页块，其中每个页块的大小为2幂次个页（4K*2^n），把这些页块用链表相连。每个块链表分别包含大小为1，2，4，8，16，32，64，128，256，512和1024个连续页框的页框块。

页块框地起始地址：

- 每个页块的第一个页的物理地址是该块大小的整数倍。例如，大小为16个页的块，其起始地址是16*2^12（2^12=4096）的整数倍。

分配页块时：

- 假设要申请一个256个页的块，先从256个页的链表中查找空闲块，如果没有，就去512个页的链表中找，找到了则将页块分为2个256个页的块，一个分配给应用，另外一个移到256个页的链表中。如果512不存在，接着往上找，如果1024块存在，则将其中的256页作为请求返回，剩余的768分成256块和512块分别插到相应的链表中。如果仍然没有，则返回错误。

页框块在释放时：

会迭代地主动合成为2倍大的单独页框块。两个块称为伙伴需要满足一下条件：

- 两个块具有相同的大小
- 它们的物理地址是连连续的。
- 第一块的第一个页框的物理地址是2*b*2^12的倍数。

内存中的数据结构
---
  包含一个11元素、元素类型为free_area的一个数组，每个元素对应一块大小。
  
   free_area每个元素中有一个free_list，表示双向循环链表的头，这个双向循环链表集中了大小为2^k页的空闲块对应的页描述符。该链表包含每个空闲页框块（大小为2^k）的起始页框的页描述符。指向链表中相邻元素的指针存放在页描述符的lru字段中。
   
   free_area每个元素还包含一个nr_free字段，它指定了大小为2^k的页框块个数。当然，如果没有大小为2^k的空闲页框块，则nr_free等于0且free_list为空。
   
   一个空闲块的第一个页的描述符的private字段存放了块的order，也就是k。正式由于这个字段，当页框被释放时，内核可以确定这个块的伙伴是否也空闲。如果是的话就可以把两个块合成一个2^(i+1)的块。
   
5、操作系统常用的调度算法
---
（1）批处理作业调度算法
   
   1、先来先服务调度算法（FCFS）  优点公平，缺点短作业饿死
      
   2、短作业优先调度算法(SPF)     长作业不满
     
   3、最高响应比优先算法(HRN)     响应比＝（等待时间＋运行时间）/运行时间，权衡等待时间和运行时间
     
   4、基于优先数调度算法(HPF)     加入优先级
     
   5、均衡调度算法，即多级队列调度算法

（2）进程调度算法

   1、先进先出算法      针对就绪队列中的进程而言，比如一个进程没有拿到锁进入就绪队列中
      
   2、时间片轮转算法     分时系统的一种调度算法
      
   3、最高优先级算法(HPF)   优先级
      
   4、多级队列反馈法
      
（3）虚拟页式存储管理中的页面置换算法
  
   1、先进先出页面置换算法    最早进入内存的页面先失效
     
   2、最近最久未使用算法
      
   3、最少使用算法
   
 ## 多级反馈队列（最优）
 
设置多个就绪队列，并为各个队列赋予不同的优先级。第一个队列的优先级最高，第二个队列次之等。赋予各个队列的时间片的大小也各不相同，优先级越高的，时间片越短。

（1）当一个新进程进入内存后，首先将它放入第一队列的末尾，按先来先服务原则排队等待调度。如果未能在第一队列做完，就接着放到第二队列

（2）仅当第1～(i-1)队列均空时，才会调度第i队列中的进程运行。比如现在1、2队列都为空，正在第3个队列执行，这时1又加入了一个，1队列会抢占正在运行进程的处理机，优先执行1中任务。  
   
6、进程同步与互斥
---
原子操作、信号量机制、自旋锁管程、会合、分布式系统

7、线程同步的方式
---
（1）临界区  CCriticalSection

（2）信号量

（3）互斥量
 
（4）条件变量（事件）:通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作。

- 生产者和读者问题
```
#define N 100 //缓冲区大小
typedef int semaphore;
semaphore mutex=1;
semaphore empty=N;
semaphore full=0;

void producer(){
    while(true){
        int item=produce_item();
        down(&empty);
        down(&mutex);
        insert_item(item);
        up(&mutex);
        up(&full);
    }
}
void customer(){
    while(true){
        down(&full);
        down(&mutex);
        int item=remove_item();
        custome_item(item);
        up(&mutex);
        up(&empty);
    }
}
```

- 读者和作家问题
```
typedef int semaphore;
semaphore count_mutex=1;
semaphore date_mutex=1;
int count=0;

void reader()
{
    while(true){
        down(&count_mutex);
        count++;
        if(count==1) down(&date_mutex);
        up(&count_mutex);
        read();
        down(&count_mutex);
        count--;
        if(count == 0 )  up(&date_mutex);
        up(&count_mutex);        
    }
}
void writer()
{
    while(true)
    {
        down(&date_mutex);//只要有一个读者看书，作家就拿不到锁
        write();
        up(&date_mutex);
    }
}
```

8、死锁
---
（1）什么是死锁？死锁产生的条件？

在两个或者多个并发进程中，如果每个进程持有某种资源而又等待其它进程释放它或它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁。通俗的讲就是两个或多个进程无限期的阻塞、相互等待的一种状态。死锁产生的四个条件（有一个条件不成立，则不会产生死锁）
* 互斥条件：一个资源一次只能被一个进程使用
* 请求与保持条件：一个进程因请求资源而阻塞时，对已获得资源保持不放
* 不剥夺条件：进程获得的资源，在未完全使用完之前，不能强行剥夺
* 循环等待条件：若干进程之间形成一种头尾相接的环形等待资源关系

（2）死锁的处理策略：

解决死锁的基本方法如下：预防死锁、避免死锁、检测死锁、解除死锁（破坏四个条件之一）

- 1 死锁的避免  银行家算法。会产生很大的系统开销
也可以用死锁检测法，即允许死锁发生，固定时间运行程序检查有没有死锁，有的话执行解除程序。比如根据进程的优先级回收某个进程的资源
- 2 进程在请求资源却拿不到时，先暂时适当自己的所有资源。破坏保持和请求资源
- 3 进程给所有需要的资源编号，按照序号去拿资源。也就是把资源中所有的资源编号，进程在申请资源时，必须严格按照资源编号的递增次序进行，否则操作系统不予分配。破坏环路条件

9、动态链接库与静态链接库的区别
---
   静态库一般一个文件就是一个函数，调用的时候按函数功能进行调用。静态库很方便，如果一个文件中包含了多个文件，但是如果我们只是想用库中的某一个函数，却仍然得把所有的内容都链接进去。而且如果要调用多次，那么静态链接会有多个文件的副本。一个更现代的方法则是使用共享库，避免了在文件中静态库的大量重复。

   动态库函数的可执行代码位于一个.dll文件中，该dll包含一个或多个已被编译，链接并与使用它们的进程分开储存的函数。执行到某个函数时在.dll中进行查找。

   静态库在生成执行文件之前的链接过程中，也就是在编译的时候，就将库函数装在到程序中去了，而动态库函数必须在运行的时候才被装载，所以使用静态库速度快一些。

`1 库是什么`
```cpp
答：库就是一个.o 二进制文件，就是一个加密操作；静态库在程序编译时会被连接到目标代码中，程序运行时将不再需要，动态库在程序编译时并不会被连接到目标代码中，而是在程序运行是才被载入，因此在程序运行时还需要动态库存在。
win           linux
.dll             .so    ------->动态库
.lib             .a    --------->静态库
```
`2、静态库的制作`
```cpp
linux下命名规则  libxxx.a   固定前后，中间可以自己写
准备好 a.c  b.c文件
gcc -c *.c -c     //生成.o文件
ar rcs libtest.a  a.o b.o   //打包
num libtest.a    //查看静态库中有几个.o文件

用户调静态库
根据给出的 .h文件写 main.c
gcc main.c -I ./include  -L ./lib  -l test  -o app
          头文件路径   -L静态库路径  -l 静态库名称，去掉lib和.a
gcc ./app 
```
`3、动态库  生成可执行文件`
```cpp
linux下命名规则  libxxx.so
gcc a.c b.c -c -fpic
gcc -shared -o libxxx.so a.o b.o

用户调
gcc main.c -I ./include/ -L ./lib/ -l test -o app
./app
一定要把动态库加入到 环境变量中
export LD_LIBRARY_PATH = 动态库路径。
ldd app   ----->查看文件运行需要的所有库 
```

10、中断与系统调用
---

11、颠簸
---
　　颠簸本质上是指频繁的页调度行为，具体来讲，进程发生缺页中断，这时，必须置换某一页。然而，其他所有的页都在使用，它置换一个页，但又立刻再次需要这个页。因此，会不断产生缺页中断，导致整个系统的效率急剧下降，这种现象称为颠簸（抖动）。

　　内存颠簸的解决策略包括：

如果是因为页面替换策略失误，可以修改替换算法来解决这个问题；

如果是因为运行的程序太多，造成程序无法同时将所有频繁访问的页面调入内存，则要降低多道程序的数量；

否则，还剩下两个办法：终止该进程或增加物理内存容量。

12为什么进程上下文切换比线程上下文切换代价高？
---
进程切换分两步：

- 1.切换页目录以使用新的地址空间
- 2.切换内核栈和硬件上下文

对于linux来说，线程和进程的最大区别就在于地址空间，对于线程切换，第1步是不需要做的，第2是进程和线程切换都要做的。

切换的性能消耗：

1、线程上下文切换和进程上下问切换一个最主要的区别是线程的切换虚拟内存空间依然是相同的，但是进程切换是不同的。这两种上下文切换的处理都是通过操作系统内核来完成的。内核的这种切换过程伴随的最显著的性能损耗是将寄存器中的内容切换出。

2、另外一个隐藏的损耗是上下文的切换会扰乱处理器的缓存机制。简单的说，一旦去切换上下文，处理器中所有已经缓存的内存地址一瞬间都作废了。还有一个显著的区别是当你改变虚拟内存空间的时候，处理的页表缓冲（processor's Translation Lookaside Buffer (TLB)）或者相当的神马东西会被全部刷新，这将导致内存的访问在一段时间内相当的低效。但是在线程的切换中，不会出现这个问题。


